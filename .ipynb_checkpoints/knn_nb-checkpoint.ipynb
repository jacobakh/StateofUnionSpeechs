{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An analysis of the State of the Union speeches - k nearest neighbors\n",
    "\n",
    "In this notebook, you should explore one question or idea of your own from this dataset.  Provide the code and computations here, and summarize your points in the [main](main.ipynb) notebook.\n",
    "\n",
    "# K-Nearest Neighbors \n",
    "\n",
    "In our previous notebooks, we've turned each speech in the dataset into a vector in $\\mathbb{R}^{n}$ where $n$ is the number of words across all of the speeches. Each speech vector $\\vec{v} \\in \\mathbb{R}^{n}$ represents a *count* of the number of occurrences of a particular word in that speech. For example, if George Washington's first state of the union used the word \"America\" 12 times, then the corresponding entry in that speech's vector would have a value of $12$. \n",
    "\n",
    "We want to use this data representation to train a classification algorithm known as **k-nearest neighbors**. We use a training set consisting of some of the Presidential speeches to train the algorithm. The vectors correspond to the data points, which the President who delivered the speech is the class label (so we have 45 class labels in total). Now, the algorithm has a set of \"speeches\" in $\\mathbb{R}^{n}$, each of which is labeled with a speaker. \n",
    "\n",
    "When predicting the speaker of a speech outside the training dataset, the algorithm looks the $k$ (say, 4$) \"nearest\" neighbors in this high-dimensional space and takes a vote amongst their labels. For example, the 4 nearest neighbors of a test data point might have labels George Washington, George Washington, George Washington, and Thomas Jefferson. The algorithm takes a plurality vote of the k-nearest neighbors, which in this case indicates that George Washington is most likely the person who delivered the speech. \n",
    "\n",
    "## Algorithmic Choices \n",
    "\n",
    "The k-nearest neighbors algorithm requires an integer choice of $k$, a notion of \"distance\" in the space being used (in our case, $\\mathbb{R}^{n}$), and a way of weighting the labels of the nearest neighbors. While we explore different values of $k$ in \"Grid Search\" below, we fix the weighting method and distance metric in our analysis. \n",
    "\n",
    "1. **Inverse-distance weighting**: A naive approach to k-nearest neighbors is to look at the class labels of the k-nearest neighbors and then take a simple vote of these labels. Inverse distance weighting gives more preference to \"closer\" neighbors, since these are more \n",
    "\n",
    "2. **Choice of distance metric**: Typically one might use the $\\ell_{2}$ norm $\\mathbb{R}^{n}$ as a measure of distance. But since our word-vectors measure a discrete probability distribution over $n$ words, we felt that the Jensen-Shannon Distance made more sense as a measure of difference between speeches. \n",
    "\n",
    "## Pre-Processing\n",
    "\n",
    "Here, we access the previous vectorized speech data, and pre-process by: \n",
    "\n",
    "1. Scaling the data so that the entries in each vector add up to $100$. This is necessary in a k-nearest neighbors algorithm because otherwise the distance from one vector to another is dominated by the components which happen to take on a larger range of values. \n",
    "\n",
    "2. Separating the data into a test and training set. The test set consists of 1 speech for each president, while the training set is all other speeches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#load the data \n",
    "\n",
    "#scale the data \n",
    "scaler = MinMaxScaler(feature_range=(0, 100))\n",
    "\n",
    "#separate into a training and test set, with labels and vector values.\n",
    "\n",
    "#generate some synthetic data \n",
    "#TODO REMOVE THIS\n",
    "labels = ['Jon', 'Bob', 'Mal', 'Bro', 'Sav', 'Man', 'Pig', 'Bear', 'Har', 'Rar']\n",
    "vecs = np.random.uniform(400, 10)\n",
    "all_labels = [labels[np.random.randint(len(labels))] for _ in range(400)]\n",
    "speech_data = pd.DataFrame(data=vecs, index=all_labels)\n",
    "\n",
    "\n",
    "#initialize training and test data to be empty copies of the speech dataframe\n",
    "#TODO REMOVE THIS\n",
    "training_data = pd.DataFrame(columns=speech_data.columns, index=speech_data.index)\n",
    "test_data = pd.DataFrame(columns=speech_data.columns, index=speech_data.index)\n",
    "\n",
    "all_label_values = set(speech_data.index.values)\n",
    "for name in all_label_values: \n",
    "    #select a random speech given by the president with NAME\n",
    "    speeches = speech_data.loc[name]\n",
    "    test_index = np.random.randint(len(speeches))\n",
    "    test_speech = speeches.iloc[test_index]\n",
    "    \n",
    "    #append the test_speech to test_data\n",
    "    test_data = test_data.append(test_speech)\n",
    "    \n",
    "    #append everything except the test_speech to the training data\n",
    "    training_data = training_data.append(speeches.iloc[:test_index, :])\n",
    "    training_data = training_data.append(speeches.iloc[test_index + 1: , :])\n",
    "\n",
    "#Drop the rows of NaN from both dataframes\n",
    "test_data = test_data.dropna()\n",
    "training_data = training_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best k\n",
    "\n",
    "The number of neighbors to consider in k-nearest neighbors (that is, the value of $k$) is an important hyperparameter for which different choices might yield varying levels of accuracy. We do a search over $k \\in \\{1, 2, 3, 4, 5, 6, 7, 8\\}$ to decide which $k$ best minimizes the test error. The error measure is simply the number of speeches that are correctly classified. \n",
    "\n",
    "First, we'll set up the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import entropy\n",
    "\n",
    "'''We will use J-S divergence as the metric in K-Nearest Neighbors'''\n",
    "def JSdiv(p, q):\n",
    "    \"\"\"Jensen-Shannon divergence.\n",
    "    \n",
    "    Compute the J-S divergence between two discrete probability distributions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    p, q : array\n",
    "        Both p and q should be one-dimensional arrays that can be interpreted as discrete\n",
    "        probability distributions (i.e. sum(p) == 1; this condition is not checked).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The J-S divergence, computed using the scipy entropy function (with base 2) for\n",
    "        the Kullback-Leibler divergence.\n",
    "    \"\"\"\n",
    "    m = (p + q) / 2\n",
    "    return (entropy(p, m, base=2.0) + entropy(q, m, base=2.0)) / 2\n",
    "\n",
    "'''Returns the percentage of the predicted labels which match the actual labels, as \n",
    "well as a list of the misclassified labels.'''\n",
    "def accuracy_rate(predicted_labels, actual_labels): \n",
    "    assert len(predicted_labels) == len(actual_labels), 'Different number of predictions than actual cases.'\n",
    "    \n",
    "    num_labels = len(predicted_labels)\n",
    "    misclassified_presidents = []\n",
    "    \n",
    "    for i in range(len(predicted_labels)):\n",
    "        if predicted_labels[i] != actual_labels[i]: \n",
    "            misclassified_presidents.append(actual_labels[i])\n",
    "\n",
    "    accuracy_rate = (num_labels - len(misclassified_presidents))/num_labels\n",
    "    return accuracy_rate, misclassified_presidents\n",
    "\n",
    "'''Trains a k-nearest neighbor classifier using J-S divergence as a metric and weighting by \n",
    "inverse distance. Returns the rate of correct speaker classification - that is, the rate at which\n",
    "the predicted speaker of a speech in the test dataset is the actual speaker.'''\n",
    "def knn_train_and_predict(k, train_speeches, train_labels, test_speeches, test_labels): \n",
    "    #instantiate an instance of the model \n",
    "    model = KNeighborsClassifier(n_neighbors=k, weights='distance', metric=JSdiv)\n",
    "    \n",
    "    #fit the model on the training data   \n",
    "    model.fit(train_speeches, train_labels)\n",
    "    \n",
    "    #predict on the test data\n",
    "    prediction = model.predict(test_speeches)\n",
    "    \n",
    "    #compute accuracy rate \n",
    "    test_accuracy, misclassified_presidents = accuracy_rate(prediction, test_labels)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll look at the accuracy for different $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k=1 was 0.1\n",
      "Accuracy for k=2 was 0.1\n",
      "Accuracy for k=3 was 0.1\n",
      "Accuracy for k=4 was 0.1\n",
      "Accuracy for k=5 was 0.1\n",
      "Accuracy for k=6 was 0.1\n",
      "Accuracy for k=7 was 0.1\n",
      "Accuracy for k=8 was 0.1\n"
     ]
    }
   ],
   "source": [
    "k_accuracy = {}\n",
    "for k in range(1, 9): \n",
    "    test_accuracy = knn_train_and_predict(k, training_data, training_data.index.values, test_data, test_data.index.values)\n",
    "    print('Accuracy for k={} was {}'.format(k, test_accuracy))\n",
    "    k_accuracy[k] = test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a plot of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuoAAAICCAYAAACZcOhJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b2cfda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot([k for k in range(1, 9)], [k_accuracy[k] for k in range(1, 9)])\n",
    "plt.title('Accuracy Rate of k-nearest neighbors classifier', fontsize=24)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.xlabel('Value of k', fontsize=20)\n",
    "plt.savefig('fig/knn_hyperparam.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanations for Misclassification \n",
    "\n",
    "The assumption in our model before was that Presidents tend to give similar speeches over time, and so the vectors corresponding to their speeches were closer together in $\\mathbb{R}^{n}$ than the vectors corresponding to the speeches of another President. Therefore, one reason for misclassification might be that a President gave *substantially different* speeches over time, and so the nearest neighbors of a test point are not actually the same as the President. \n",
    "\n",
    "For example, George W. Bush might have given very different speeches before and after 9/11. Therefore, if we train on Bush's post-9/11 speeches, then the classifier wouldn't predict his pre 9/11 speeches very well, and might classify them as some other president. \n",
    "\n",
    "One way to measure this phenomenon is analyzing the **variance across speeches** for each president. We hypothesize that the presidents who are misclassified are likely the ones whose speeches have a high variance. \n",
    "\n",
    "\n",
    "### Finding the misclassified Presidents \n",
    "\n",
    "We've found that the best $k$ is $k = 5$ (TODO TODO TODO TODO). Now, let's look at which Presidents get misclassified by the k-nearest neighors algorithm, even with the best k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mal', 'Bro', 'Man', 'Har', 'Sav', 'Rar', 'Bob', 'Pig', 'Jon']\n"
     ]
    }
   ],
   "source": [
    "#    test_accuracy, misclassified_presidents = knn_train_and_predict(k, training_data, \n",
    "#training_data.index.values, test_data, test_data.index.values)\n",
    "\n",
    "best_model = KNeighborsClassifier(n_neighbors=5, weights='distance', metric=JSdiv)\n",
    "    \n",
    "#fit the model on the training data   \n",
    "best_model.fit(training_data, training_data.index.values)\n",
    "\n",
    "#predict on the test data\n",
    "prediction = best_model.predict(test_data)\n",
    "\n",
    "#compute accuracy rate \n",
    "test_accuracy, misclassified_presidents = accuracy_rate(prediction, test_data.index.values)\n",
    "print(misclassified_presidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Variance Across Speeches\n",
    "\n",
    "Let's figure out what the variance of each President's speeches is. A natural measure of the variance of speeches is the **generalized Jensen-Shannon divergence** [source](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence). \n",
    "\n",
    "Suppose that a president gave $q$ speeches $v_1, ..., v_q \\in \\mathbb{R}^{n}$. If $H$ is the Shannon entropy function, and $\\pi_1, ..., \\pi_q$ are weights such that $\\sum\\limits_{i = 1}^{q} \\pi_{i} = 1$, then the generalized JS divergence of $v_1, ..., v_q$ is simply \n",
    "\n",
    "$$H(\\sum\\limits_{i = 1}^{q} \\pi_{i} v_{i}) - \\sum\\limits_{i = 1}^{q} \\pi_{i} H(v_{i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generalized_JS_divergence(speeches_df): \n",
    "    avg_speech = np.mean(speeches_df, axis=0)\n",
    "    entropy_of_average = entropy(avg_speech)\n",
    "    speech_entropies = speeches_df.apply(entropy, axis=1)\n",
    "    average_of_entropy = np.mean(speech_entropies)\n",
    "    return entropy_of_average - average_of_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031606004360585249"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "js_test_speeches = training_data.loc['Bear'] + 4\n",
    "scale_to_sum_one = lambda vec: vec/sum(vec)\n",
    "js_test_speeches = js_test_speeches.apply(scale_to_sum_one, axis=1)\n",
    "generalized_JS_divergence(js_test_speeches)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
